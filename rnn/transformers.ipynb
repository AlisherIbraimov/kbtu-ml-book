{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers were introduced in 2017 by Google Brain researchers and have since revolutionized the field of machine learning, particularly in processing sequential data like text. Their architecture allows them to handle entire sequences of data simultaneously, which is a major shift from the previous models that processed data one element at a time. This makes transformers not only more efficient in understanding context in tasks like language processing but also faster to train due to their parallel processing capabilities. Their versatility has also led to significant advancements in various areas beyond language, like computer vision and audio processing, making them a popular choice in the field of artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution of Text Processing Approaches Prior to Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bag-of-Words model was one of the earliest and simplest techniques. It involved representing text data as a bag of words, essentially a set where the order of words didn’t matter, only their frequency. While easy to understand and implement, this approach had significant drawbacks. It couldn't capture the context or the ordering of words, making it limited in handling complex language tasks. For example, it couldn't differentiate between \"dog bites man\" and \"man bites dog,\" since both sentences contain the same words with the same frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrent Neural Networks (RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs marked a significant advancement. They processed text sequences word by word and could remember information from previous words. This sequential processing made them better at understanding context compared to Bag-of-Words. However, RNNs struggled with long sequences. They often failed to remember information from the beginning of the text by the time they reached the end, a problem known as \"short-term memory.\" This made them less effective for tasks involving longer texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long Short-Term Memory networks (LSTMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTMs were developed to address the short-term memory issue of RNNs. LSTMs could remember information over longer periods, making them more suitable for complex language tasks involving longer sequences. But, they still processed data sequentially, which made training them time-consuming and computationally expensive, especially with large datasets. This sequential processing also limited their ability to be parallelized, a key factor in speeding up the training of machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Attention is All You Need\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, in 2017, a groundbreaking paper titled \"Attention Is All You Need\" was written by researchers at Google Brain, introducing the world to the transformer model. This paper marked a significant shift in how machine learning models handle sequential data, like text. The researchers proposed a new architecture that, unlike its predecessors, didn't rely on sequential data processing methods like RNNs and LSTMs. Instead, it introduced the concept of 'attention mechanisms', which allowed the model to focus on different parts of the input data, enhancing its ability to understand context and relationships within the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"assets/attention.png\" width=\"500\" height=\"600\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image illustrates the transformer architecture as explained in the original paper \"Attention Is All You Need.\" It provides a visual representation of the complex mechanisms that power the transformer model. Using this diagram as a guide, we'll delve into understanding how a transformer processes information. Specifically, we will explore the process of translating a sentence from English to Russian, dissecting how the model's components interact to achieve accurate and context-aware translation. Through this architecture, we'll see the journey of data from input to output, learning the roles of embeddings, attention mechanisms, and neural network layers in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we have the task of translating a sentence from English to Russian, the transformer architecture facilitates this process through several intricate steps. For instance, the sentence \"I love Machine Learning\" would be translated into Russian as \"Я люблю Машинное Обучение.\" To accomplish this task using the transformer architecture, the model performs a series of complex operations, each contributing to the accurate translation of the sentence, capturing the essence and context of the original English phrase into its Russian counterpart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** After each step, a dummy code example will be used to illustrate the idea. This allows us to demonstrate the concept without introducing the complexity of actual mechanisms used in transformers. In the original transformer architecture, the mechanisms behind the scenes are more complicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Tokenization and Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to prepare the input sentence for the model. The sentence \"I love Machine Learning\" is broken down into tokens. In this case, tokens could correspond to words or subwords. This process is known as tokenization. Each token is then converted into a numerical representation called an embedding. These embeddings are vectors that capture the meaning of the tokens in a high-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "# The sentence is split into tokens (words in this case).\n",
    "tokens = \"I love Machine Learning\".split()\n",
    "\n",
    "# Assuming we have a predefined vocabulary with associated simple embeddings.\n",
    "vocabulary = {\n",
    "    \"I\": [1, 0, 0],\n",
    "    \"love\": [0, 1, 0],\n",
    "    \"Machine\": [0, 0, 1],\n",
    "    \"Learning\": [1, 1, 0]\n",
    "}\n",
    "\n",
    "# Convert each token into its corresponding embedding from the vocabulary.\n",
    "embeddings = [vocabulary[token] for token in tokens]\n",
    "\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In a real-world scenario, embeddings are multi-dimensional and complex. Advanced tokenization methods like Byte Pair Encoding (BPE) are employed to optimize the tokenization process, providing a more efficient and meaningful representation of language data. BPE, for example, segments text into a set of frequent subwords, which enables the model to effectively handle a wide range of words, including rare and compound words. This approach not only improves the quality of embeddings by capturing subword-level information but also aids in managing vocabulary size, enhancing the model's robustness and versatility in language comprehension and processing.\n",
    "\n",
    "Furthermore, these sophisticated embeddings are designed such that words with similar meanings are positioned closely in the multi-dimensional vector space. This proximity in vector space is crucial, as it allows the model to recognize and utilize the semantic relationships between words, enhancing its ability to understand and generate coherent and contextually relevant language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tokenization and embedding, each embedding receives a positional encoding. This step is essential because, unlike RNNs, the transformer architecture doesn't inherently process the sequence order. Positional encodings add information to each token's embedding to provide the model with the sequence order of the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1, 0.1, 0.1], [0.2, 1.2, 0.2], [0.3, 0.3, 1.3], [1.4, 1.4, 0.4]]\n"
     ]
    }
   ],
   "source": [
    "dimensionality = len(embeddings[0])  # Ensure positional encodings match the dimensionality of the embeddings\n",
    "\n",
    "# Generate simplified positional encodings, scaled to not overpower the embeddings\n",
    "positional_encodings = [[(i+1) / 10] * dimensionality for i in range(len(embeddings))]\n",
    "\n",
    "# Combine the positional encodings with the original embeddings\n",
    "encoded_embeddings = [[e + p for e, p in zip(embedding, pos_encoding)] \n",
    "                      for embedding, pos_encoding in zip(embeddings, positional_encodings)]\n",
    "\n",
    "print(encoded_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.1, 0.1, 0.1], [0.2, 1.2, 0.2], [0.3, 0.3, 1.3], [1.4, 1.4, 0.4]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each vector now contains both the semantic meaning from the original embeddings and the positional information.\n",
    "[\n",
    " [1.1, 0.1, 0.1],  # Encoded embedding for \"I\"\n",
    " [0.2, 1.2, 0.2],  # Encoded embedding for \"love\"\n",
    " [0.3, 0.3, 1.3],  # Encoded embedding for \"Machine\"\n",
    " [1.4, 1.4, 0.4]   # Encoded embedding for \"Learning\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real-world transformers, positional encodings are created using sine and cosine functions and added to the word embeddings. This gives each word a unique position in the sentence. Sine and cosine are used because they create wave-like patterns that are different for each position and repeat in a predictable way. This repeating pattern helps the transformer understand very long sentences without getting confused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Self-Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding positional encodings to the embeddings, the next step in the transformer architecture is the self-attention mechanism. This is where the transformer starts to analyze and interpret the sentence, focusing on different parts of it to understand the context and relationships between words.\n",
    "\n",
    "In the self-attention process, the model calculates attention scores for each word in relation to every other word in the sentence. This means it assesses how much focus should be put on other words when considering each specific word. For example, in our sentence \"I love Machine Learning,\" the model might learn to pay more attention to \"love\" when processing the word \"Machine Learning,\" since these words are closely related in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0473684210526315, 0.8184210526315789, 0.4], [0.8173913043478261, 1.0695652173913044, 0.4434782608695653], [0.7136363636363635, 0.7568181818181816, 0.7181818181818181], [0.9152173913043478, 0.95, 0.4326086956521739]]\n"
     ]
    }
   ],
   "source": [
    "def simplified_self_attention(encoded_embeddings):\n",
    "    attention_scores = []\n",
    "\n",
    "    # Iterate over each word embedding in the sentence\n",
    "    for word_embedding in encoded_embeddings:\n",
    "        scores = []\n",
    "\n",
    "        # For each word, calculate its attention score with every other word\n",
    "        for other_embedding in encoded_embeddings:\n",
    "            # Simplified calculation: dot product of the two embeddings\n",
    "            score = sum(e1 * e2 for e1, e2 in zip(word_embedding, other_embedding))\n",
    "            scores.append(score)\n",
    "\n",
    "        # Collect the scores for this word against all other words\n",
    "        attention_scores.append(scores)\n",
    "\n",
    "    # Normalize the scores for each word to create attention weights\n",
    "    # This converts them into probabilities that sum up to 1\n",
    "    attention_weights = [[s / sum(scores) for s in scores] for scores in attention_scores]\n",
    "\n",
    "    # Apply the calculated attention weights to the embeddings\n",
    "    attended_embeddings = []\n",
    "    for i, weights in enumerate(attention_weights):\n",
    "        # Initialize a zero vector for the attended embedding\n",
    "        attended_embedding = [0] * len(encoded_embeddings[0])\n",
    "\n",
    "        # Apply each weight to the corresponding word embedding\n",
    "        for j, weight in enumerate(weights):\n",
    "            # Update the attended embedding by adding weighted contributions from all embeddings\n",
    "            attended_embedding = [e + weight * encoded_embeddings[j][k] for k, e in enumerate(attended_embedding)]\n",
    "\n",
    "        # Store the attended embedding for this word\n",
    "        attended_embeddings.append(attended_embedding)\n",
    "\n",
    "    return attended_embeddings\n",
    "\n",
    "# Applying the simplified self-attention to our encoded embeddings\n",
    "attention_output = simplified_self_attention(encoded_embeddings)\n",
    "\n",
    "print(attention_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates a very basic version of self-attention. In reality, the process is much more complex, involving matrices called 'queries', 'keys', and 'values', which are derived from the embeddings and used to compute the attention scores in a more sophisticated way. This mechanism allows the transformer to capture and utilize the contextual relationships within the sentence, which is essential for understanding and generating human-like language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the term \"multi-head\" in the context of self-attention is used. It refers to the model's ability to pay attention to different parts of the sentence in multiple, distinct ways at the same time. Imagine it as having multiple 'heads', each looking at the sentence from a different perspective or focusing on different types of relationships between words. This allows the transformer to capture a more comprehensive understanding of the text, as each 'head' might pick up on different nuances or aspects of the sentence. Essentially, multi-head attention provides a richer, more diverse interpretation of the sentence compared to using a single perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the self-attention mechanism has processed the sentence \"I love Machine Learning\" and given us new, contextually-rich embeddings, the next step in a transformer involves a feed-forward neural network. This network works on each word's embedding separately but in the same way for each word.\n",
    "\n",
    "Think of it as a kind of filter that further refines the meaning of each word. For our translation task, this step is like fine-tuning the understanding of each word (\"I\", \"love\", \"Machine\", \"Learning\") in the context of the whole sentence.\n",
    "\n",
    "The feed-forward network in the transformer consists of two layers. It takes the output from the self-attention mechanism, processes it through these layers, and then outputs new embeddings. These new embeddings are still about the same words, but now they've been adjusted even more based on the context of the whole sentence.\n",
    "\n",
    "In the context of translating from English to Russian, this step helps to ensure that each word's meaning is as accurate and contextually appropriate as possible before the final translation is generated. It's like making sure each piece of the puzzle is in its best form before putting the whole puzzle together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06797368421052633, 0.06797368421052633, 0.06797368421052633], [0.06991304347826088, 0.06991304347826088, 0.06991304347826088], [0.0656590909090909, 0.0656590909090909, 0.0656590909090909], [0.06893478260869566, 0.06893478260869566, 0.06893478260869566]]\n"
     ]
    }
   ],
   "source": [
    "def simplified_feed_forward_network(attention_output):\n",
    "    # Dummy parameters for the feed-forward network\n",
    "    hidden_layer_size = 5  # Typically much larger in real transformers\n",
    "    output_size = len(attention_output[0])  # Same as the input size\n",
    "\n",
    "    # Simple feed-forward network with one hidden layer\n",
    "    for i, word_embedding in enumerate(attention_output):\n",
    "        # Simulate a hidden layer with arbitrary transformation\n",
    "        hidden_layer = [sum(word_embedding) * 0.1] * hidden_layer_size\n",
    "\n",
    "        # Simulate an output layer that brings the dimensions back to the original embedding size\n",
    "        output_embedding = [sum(hidden_layer) / hidden_layer_size] * output_size\n",
    "\n",
    "        # Update the attention output with the output of the feed-forward network\n",
    "        attention_output[i] = output_embedding\n",
    "\n",
    "    return attention_output\n",
    "\n",
    "# Applying the simplified feed-forward network to the output of the self-attention mechanism\n",
    "transformed_output = simplified_feed_forward_network(attention_output)\n",
    "\n",
    "print(transformed_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the provided code, we're running a simple feed-forward network on each word's embedding from the self-attention output. This network, with a basic transformation in the hidden layer followed by an output layer, alters each embedding. The purpose is to refine the understanding of each word in the sentence context. The result is a new set of embeddings, modified by this process, representing a more nuanced understanding of each word.\n",
    "\n",
    "In actual transformers, the process is more intricate. The real feed-forward network uses complex layers and non-linear functions to deeply process each embedding. This advanced processing captures finer details and subtleties in the data, crucial for tasks like translation, where nuances in meaning and context greatly influence the output quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 4 steps are done in the Encoder part of the transformer's architecture. Then, the result from the encoder goes to the decoder part. Both of these components have their own roles.\n",
    "\n",
    "Encoder's Role:\n",
    "\n",
    "1. Understanding the Sentence: \n",
    "   - The Encoder processes the English sentence \"I love Machine Learning\" through tokenization, embedding, adding positional encodings, self-attention, and a feed-forward neural network.\n",
    "  \n",
    "2. Creating Contextual Representations: \n",
    "   - It transforms the sentence into a set of vectors that represent not just the words, but also their context and relationship within the sentence.\n",
    "\n",
    "\n",
    "\n",
    "Decoder's Role:\n",
    "\n",
    "1. Receiving Encoder's Output: \n",
    "   - The Decoder receives these contextual vectors from the Encoder.\n",
    "\n",
    "2. Translating Step by Step: \n",
    "   - It begins translating the sentence into Russian, one word at a time, using its self-attention and feed-forward layers, based on the Encoder's output.\n",
    "\n",
    "3. Considering Context and Previous Translation: \n",
    "   - The Decoder checks what it has already translated, ensuring each new word aligns with the previous ones for contextual accuracy.\n",
    "\n",
    "4. Final Output: \n",
    "   - This results in the Russian translation \"Я люблю Машинное Обучение\".\n",
    "\n",
    "The Encoder processes and understands the original sentence, while the Decoder uses this information to generate an accurate and coherent translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"NDPrPDZfUpbR\" data-shufflequestions=\"False\"\n",
       "               data-shuffleanswers=\"True\"\n",
       "               data-preserveresponses=\"false\"\n",
       "               data-numquestions=\"1000000\"\n",
       "               data-maxwidth=\"600\"\n",
       "               style=\"border-radius: 10px; text-align: left\"> <style>\n",
       "#NDPrPDZfUpbR {\n",
       "   --jq-multiple-choice-bg: #6f78ffff;\n",
       "   --jq-mc-button-bg: #fafafa;\n",
       "   --jq-mc-button-border: #e0e0e0e0;\n",
       "   --jq-mc-button-inset-shadow: #555555;\n",
       "   --jq-many-choice-bg: #f75c03ff;\n",
       "   --jq-numeric-bg: #392061ff;\n",
       "   --jq-numeric-input-bg: #c0c0c0;\n",
       "   --jq-numeric-input-label: #101010;\n",
       "   --jq-numeric-input-shadow: #999999;\n",
       "   --jq-incorrect-color: #c80202;\n",
       "   --jq-correct-color: #009113;\n",
       "   --jq-text-color: #fafafa;\n",
       "}\n",
       "\n",
       ".Quiz {\n",
       "    max-width: 600px;\n",
       "    margin-top: 15px;\n",
       "    margin-left: auto;\n",
       "    margin-right: auto;\n",
       "    margin-bottom: 15px;\n",
       "    padding-bottom: 4px;\n",
       "    padding-top: 4px;\n",
       "    line-height: 1.1;\n",
       "    font-size: 16pt;\n",
       "    border-radius: inherit;\n",
       "}\n",
       "\n",
       ".QuizCode {\n",
       "    font-size: 14pt;\n",
       "    margin-top: 10px;\n",
       "    margin-left: 20px;\n",
       "    margin-right: 20px;\n",
       "}\n",
       "\n",
       ".QuizCode>pre {\n",
       "    padding: 4px;\n",
       "}\n",
       "\n",
       ".Answer {\n",
       "    margin: 10px 0;\n",
       "    display: grid;\n",
       "    grid-template-columns: 1fr 1fr;\n",
       "    grid-gap: 10px;\n",
       "    border-radius: inherit;\n",
       "}\n",
       "\n",
       ".Feedback {\n",
       "    font-size: 16pt;\n",
       "    text-align: center;\n",
       "    min-height: 2em;\n",
       "}\n",
       "\n",
       ".Input {\n",
       "    align: left;\n",
       "    font-size: 20pt;\n",
       "}\n",
       "\n",
       ".Input-text {\n",
       "    display: block;\n",
       "    margin: 10px;\n",
       "    color: inherit;\n",
       "    width: 140px;\n",
       "    background-color: var(--jq-numeric-input-bg);\n",
       "    color: var(--jq-text-color);\n",
       "    padding: 5px;\n",
       "    padding-left: 10px;\n",
       "    font-family: inherit;\n",
       "    font-size: 20px;\n",
       "    font-weight: inherit;\n",
       "    line-height: 20pt;\n",
       "    border: none;\n",
       "    border-radius: 0.2rem;\n",
       "    transition: box-shadow 0.1s);\n",
       "}\n",
       "\n",
       ".Input-text:focus {\n",
       "    outline: none;\n",
       "    background-color: var(--jq-numeric-input-bg);\n",
       "    box-shadow: 0.6rem 0.8rem 1.4rem -0.5rem var(--jq-numeric-input-shadow);\n",
       "}\n",
       "\n",
       ".MCButton {\n",
       "    background: var(--jq-mc-button-bg);\n",
       "    border: 1px solid var(--jq-mc-button-border);\n",
       "    border-radius: inherit;\n",
       "    padding: 10px;\n",
       "    font-size: 16px;\n",
       "    cursor: pointer;\n",
       "    text-align: center;\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "    justify-content: center;\n",
       "}\n",
       "\n",
       ".MCButton p {\n",
       "    color: inherit;\n",
       "}\n",
       "\n",
       ".MultipleChoiceQn {\n",
       "    padding: 10px;\n",
       "    background: var(--jq-multiple-choice-bg);\n",
       "    color: var(--jq-text-color);\n",
       "    border-radius: inherit;\n",
       "}\n",
       "\n",
       ".ManyChoiceQn {\n",
       "    padding: 10px;\n",
       "    background: var(--jq-many-choice-bg);\n",
       "    color: var(--jq-text-color);\n",
       "    border-radius: inherit;\n",
       "}\n",
       "\n",
       ".NumericQn {\n",
       "    padding: 10px;\n",
       "    background: var(--jq-numeric-bg);\n",
       "    color: var(--jq-text-color);\n",
       "    border-radius: inherit;\n",
       "}\n",
       "\n",
       ".NumericQn p {\n",
       "    color: inherit;\n",
       "}\n",
       "\n",
       ".InpLabel {\n",
       "    line-height: 34px;\n",
       "    float: left;\n",
       "    margin-right: 10px;\n",
       "    color: var(--jq-numeric-input-label);\n",
       "    font-size: 15pt;\n",
       "}\n",
       "\n",
       ".incorrect {\n",
       "    color: var(--jq-incorrect-color);\n",
       "}\n",
       "\n",
       ".correct {\n",
       "    color: var(--jq-correct-color);\n",
       "}\n",
       "\n",
       ".correctButton {\n",
       "    /*\n",
       "    background: var(--jq-correct-color);\n",
       "   */\n",
       "    animation: correct-anim 0.6s ease;\n",
       "    animation-fill-mode: forwards;\n",
       "    color: var(--jq-text-color);\n",
       "    box-shadow: inset 0px 0px 5px var(--jq-mc-button-inset-shadow);\n",
       "    outline: none;\n",
       "}\n",
       "\n",
       ".incorrectButton {\n",
       "    animation: incorrect-anim 0.8s ease;\n",
       "    animation-fill-mode: forwards;\n",
       "    color: var(--jq-text-color);\n",
       "    box-shadow: inset 0px 0px 5px var(--jq-mc-button-inset-shadow);\n",
       "    outline: none;\n",
       "}\n",
       "\n",
       "@keyframes incorrect-anim {\n",
       "    100% {\n",
       "        background-color: var(--jq-incorrect-color);\n",
       "    }\n",
       "}\n",
       "\n",
       "@keyframes correct-anim {\n",
       "    100% {\n",
       "        background-color: var(--jq-correct-color);\n",
       "    }\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "var questionsNDPrPDZfUpbR=[\n    {\n        \"question\": \"What is the primary advantage of Transformer models over RNNs and LSTMs in processing text?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Lower computational cost\",\n                \"correct\": false,\n                \"feedback\": \"Not quite. Transformers typically require more computational resources.\"\n            },\n            {\n                \"answer\": \"Ability to process sequences in parallel\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Transformers can process sequences in parallel, unlike RNNs and LSTMs.\"\n            },\n            {\n                \"answer\": \"Simpler architecture\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Transformers have a more complex architecture involving attention mechanisms.\"\n            },\n            {\n                \"answer\": \"Do not require training\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Transformers, like all deep learning models, require training.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"What key innovation do Transformers introduce in natural language processing?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Sequential data processing\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Transformers move away from purely sequential processing.\"\n            },\n            {\n                \"answer\": \"Attention mechanisms\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Attention mechanisms allow the model to focus on different parts of the input data.\"\n            },\n            {\n                \"answer\": \"Bag-of-Words model\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The Bag-of-Words model is a much earlier and simpler technique.\"\n            },\n            {\n                \"answer\": \"Convolutional layers\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While convolutional layers are used in other types of neural networks, they are not the key innovation in Transformers.\"\n            }\n        ]\n    },\n\t{\n        \"question\": \"What is the first step in processing a sentence for translation in the transformer architecture?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Tokenization and Embedding\",\n                \"correct\": true,\n                \"feedback\": \"Correct! The first step involves tokenization of the sentence and converting these tokens into embeddings.\"\n            },\n            {\n                \"answer\": \"Attention Mechanism\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The attention mechanism comes into play later in the process.\"\n            },\n            {\n                \"answer\": \"Neural Network Processing\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. This is a later stage in the process after embeddings are created.\"\n            },\n            {\n                \"answer\": \"Output Generation\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Output generation is the final step in the process.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"What is the significance of embeddings in the transformer model?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"They represent tokens in a low-dimensional space\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Embeddings represent tokens in a high-dimensional space.\"\n            },\n            {\n                \"answer\": \"They are fixed numerical representations of words\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While embeddings are numerical, they are not necessarily fixed and can capture contextual meanings.\"\n            },\n            {\n                \"answer\": \"They capture the meaning of tokens in a high-dimensional space\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Embeddings are high-dimensional vectors that capture the semantic essence of tokens.\"\n            },\n            {\n                \"answer\": \"They are used only for the input sequence\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Embeddings are used for both input and output sequences in the model.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"What advanced tokenization method is commonly employed in transformers to optimize the tokenization process?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Word Level Tokenization\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Word level tokenization is more basic and less efficient than the method used in transformers.\"\n            },\n            {\n                \"answer\": \"Byte Pair Encoding (BPE)\",\n                \"correct\": true,\n                \"feedback\": \"Correct! BPE is an advanced tokenization method that segments text into frequent subwords, aiding in efficient language representation.\"\n            },\n            {\n                \"answer\": \"Character Level Tokenization\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Character level tokenization is not as efficient as BPE for transformers.\"\n            },\n            {\n                \"answer\": \"N-gram Tokenization\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. N-gram tokenization is not the primary method used in transformers.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"How do embeddings contribute to the transformer model's understanding of language?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"By providing a fixed representation of each word\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Embeddings are not just fixed representations; they capture contextual meanings.\"\n            },\n            {\n                \"answer\": \"By positioning similar words closely in the vector space\",\n                \"correct\": true,\n                \"feedback\": \"Correct! This proximity in vector space allows the model to recognize semantic relationships between words.\"\n            },\n            {\n                \"answer\": \"By reducing the dimensionality of the input data\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Embeddings are high-dimensional, not reductive.\"\n            },\n            {\n                \"answer\": \"By encoding syntax rules of the language\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Embeddings primarily capture semantic meanings, not syntactic rules.\"\n            }\n        ]\n    },\n\t{\n        \"question\": \"Why are positional encodings necessary in the transformer architecture?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"To reduce the complexity of the model\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Positional encodings are not about reducing complexity but about providing sequence order information.\"\n            },\n            {\n                \"answer\": \"To encode syntax rules\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Positional encodings are not for syntax rules, but for sequence order.\"\n            },\n            {\n                \"answer\": \"To provide the model with the sequence order of words\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Positional encodings add information about the sequence order, which is crucial for understanding the order in which words appear.\"\n            },\n            {\n                \"answer\": \"To improve the model's accuracy\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While accuracy is a goal, the primary purpose of positional encodings is to provide sequence order information.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"How do positional encodings in transformers work with word embeddings?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"They replace the original word embeddings\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Positional encodings are added to, not replace, the original embeddings.\"\n            },\n            {\n                \"answer\": \"They are added to the original word embeddings\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Positional encodings are combined with the original embeddings to provide both semantic and positional information.\"\n            },\n            {\n                \"answer\": \"They are multiplied with the original word embeddings\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Positional encodings are added, not multiplied.\"\n            },\n            {\n                \"answer\": \"They are independent of the word embeddings\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Positional encodings are directly combined with word embeddings.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"What functions are typically used to generate positional encodings in real-world transformers?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Linear and exponential functions\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Linear and exponential functions are not typically used for this purpose.\"\n            },\n            {\n                \"answer\": \"Sine and cosine functions\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Sine and cosine functions are used because of their wave-like, repeating patterns.\"\n            },\n            {\n                \"answer\": \"Tangent and cotangent functions\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Tangent and cotangent functions are not the standard for positional encodings.\"\n            },\n            {\n                \"answer\": \"Polynomial functions\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Polynomial functions are not typically used for positional encodings.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"What is the purpose of scaling positional encodings in the transformer model?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"To enhance the model's learning speed\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Scaling is not primarily for enhancing learning speed.\"\n            },\n            {\n                \"answer\": \"To ensure they do not overpower the original word embeddings\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Positional encodings are scaled to maintain a balance with the semantic information in the word embeddings.\"\n            },\n            {\n                \"answer\": \"To match the dimensionality of the neural network layers\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While dimensionality matching is important, the scaling's main purpose is balance.\"\n            },\n            {\n                \"answer\": \"To create a uniform distribution\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The scaling is not about creating a uniform distribution.\"\n            }\n        ]\n    },\n\t{\n        \"question\": \"What is the primary function of the self-attention mechanism in the transformer model?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"To translate words from one language to another\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The self-attention mechanism is about understanding relationships between words, not direct translation.\"\n            },\n            {\n                \"answer\": \"To analyze and interpret the sentence by focusing on different parts\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Self-attention allows the model to focus on different parts of the sentence to understand context.\"\n            },\n            {\n                \"answer\": \"To reduce the dimensionality of the embeddings\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Self-attention does not reduce dimensionality; it helps in understanding word relationships.\"\n            },\n            {\n                \"answer\": \"To calculate attention scores for each word in relation to other words\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While it does calculate attention scores, this is not its primary function.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"What does 'multi-head' refer to in the context of self-attention in transformers?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Multiple translation paths\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. 'Multi-head' does not refer to translation paths but to attention mechanisms.\"\n            },\n            {\n                \"answer\": \"Ability to pay attention to different sentence parts simultaneously\",\n                \"correct\": true,\n                \"feedback\": \"Correct! Multi-head attention allows the model to focus on different parts of the sentence in various ways at the same time.\"\n            },\n            {\n                \"answer\": \"Using multiple models for translation\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. It refers to the attention mechanism within a single transformer model.\"\n            },\n            {\n                \"answer\": \"Focusing on different types of relationships between words\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While this is a feature of multi-head attention, it's not the best description of what 'multi-head' means.\"\n            }\n        ]\n    },\n\t{\n        \"question\": \"What is the role of the feed-forward neural network in the transformer architecture?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"To translate words from one language to another\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While translation is an application, the feed-forward network's role is to refine word meanings.\"\n            },\n            {\n                \"answer\": \"To refine the understanding of each word in the context of the whole sentence\",\n                \"correct\": true,\n                \"feedback\": \"Correct! The feed-forward network fine-tunes the meaning of each word in the sentence's context.\"\n            },\n            {\n                \"answer\": \"To reduce the dimensionality of embeddings\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The feed-forward network does not primarily reduce dimensionality.\"\n            },\n            {\n                \"answer\": \"To create positional encodings\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Positional encodings are created before the feed-forward network stage.\"\n            }\n        ]\n    },\n\t{\n        \"question\": \"What is the primary role of the Encoder in the transformer architecture?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Translating the sentence into the target language\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The Encoder's role is to understand the original sentence, not to translate it.\"\n            },\n            {\n                \"answer\": \"Processing the sentence through various steps like tokenization, embedding, and self-attention\",\n                \"correct\": true,\n                \"feedback\": \"Correct! The Encoder processes the sentence to create contextual representations.\"\n            },\n            {\n                \"answer\": \"Generating the final output in the target language\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The final output generation is the role of the Decoder, not the Encoder.\"\n            },\n            {\n                \"answer\": \"Creating a set of vectors that represent the words and their context\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While the Encoder does this, it's not its primary role.\"\n            }\n        ]\n    },\n    {\n        \"question\": \"Which of the following is a key function of the Decoder in the transformer model?\",\n        \"type\": \"many_choice\",\n        \"answers\": [\n            {\n                \"answer\": \"Receiving contextual vectors from the Encoder\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. While this is a function of the Decoder, it's not the key function.\"\n            },\n            {\n                \"answer\": \"Translating the sentence word by word, considering context and previous translation\",\n                \"correct\": true,\n                \"feedback\": \"Correct! The Decoder translates step by step, ensuring each new word aligns with the previous ones.\"\n            },\n            {\n                \"answer\": \"Understanding the original sentence\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. Understanding the original sentence is the role of the Encoder.\"\n            },\n            {\n                \"answer\": \"Producing the final output in the target language\",\n                \"correct\": false,\n                \"feedback\": \"Incorrect. The Decoder does produce the final output, but the key function is the translation process.\"\n            }\n        ]\n    }\n];\n    // Make a random ID\nfunction makeid(length) {\n    var result = [];\n    var characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';\n    var charactersLength = characters.length;\n    for (var i = 0; i < length; i++) {\n        result.push(characters.charAt(Math.floor(Math.random() * charactersLength)));\n    }\n    return result.join('');\n}\n\n// Choose a random subset of an array. Can also be used to shuffle the array\nfunction getRandomSubarray(arr, size) {\n    var shuffled = arr.slice(0), i = arr.length, temp, index;\n    while (i--) {\n        index = Math.floor((i + 1) * Math.random());\n        temp = shuffled[index];\n        shuffled[index] = shuffled[i];\n        shuffled[i] = temp;\n    }\n    return shuffled.slice(0, size);\n}\n\nfunction printResponses(responsesContainer) {\n    var responses=JSON.parse(responsesContainer.dataset.responses);\n    var stringResponses='<B>IMPORTANT!</B>To preserve this answer sequence for submission, when you have finalized your answers: <ol> <li> Copy the text in this cell below \"Answer String\"</li> <li> Double click on the cell directly below the Answer String, labeled \"Replace Me\"</li> <li> Select the whole \"Replace Me\" text</li> <li> Paste in your answer string and press shift-Enter.</li><li>Save the notebook using the save icon or File->Save Notebook menu item</li></ul><br><br><br><b>Answer String:</b><br> ';\n    console.log(responses);\n    responses.forEach((response, index) => {\n        if (response) {\n            console.log(index + ': ' + response);\n            stringResponses+= index + ': ' + response +\"<BR>\";\n        }\n    });\n    responsesContainer.innerHTML=stringResponses;\n}\nfunction check_mc() {\n    var id = this.id.split('-')[0];\n    //var response = this.id.split('-')[1];\n    //console.log(response);\n    //console.log(\"In check_mc(), id=\"+id);\n    //console.log(event.srcElement.id)           \n    //console.log(event.srcElement.dataset.correct)   \n    //console.log(event.srcElement.dataset.feedback)\n\n    var label = event.srcElement;\n    //console.log(label, label.nodeName);\n    var depth = 0;\n    while ((label.nodeName != \"LABEL\") && (depth < 20)) {\n        label = label.parentElement;\n        console.log(depth, label);\n        depth++;\n    }\n\n\n\n    var answers = label.parentElement.children;\n\n    //console.log(answers);\n\n\n    // Split behavior based on multiple choice vs many choice:\n    var fb = document.getElementById(\"fb\" + id);\n\n\n\n\n    if (fb.dataset.numcorrect == 1) {\n        // What follows is for the saved responses stuff\n        var outerContainer = fb.parentElement.parentElement;\n        var responsesContainer = document.getElementById(\"responses\" + outerContainer.id);\n        if (responsesContainer) {\n            //console.log(responsesContainer);\n            var response = label.firstChild.innerText;\n            if (label.querySelector(\".QuizCode\")){\n                response+= label.querySelector(\".QuizCode\").firstChild.innerText;\n            }\n            console.log(response);\n            //console.log(document.getElementById(\"quizWrap\"+id));\n            var qnum = document.getElementById(\"quizWrap\"+id).dataset.qnum;\n            console.log(\"Question \" + qnum);\n            //console.log(id, \", got numcorrect=\",fb.dataset.numcorrect);\n            var responses=JSON.parse(responsesContainer.dataset.responses);\n            console.log(responses);\n            responses[qnum]= response;\n            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));\n            printResponses(responsesContainer);\n        }\n        // End code to preserve responses\n        \n        for (var i = 0; i < answers.length; i++) {\n            var child = answers[i];\n            //console.log(child);\n            child.className = \"MCButton\";\n        }\n\n\n\n        if (label.dataset.correct == \"true\") {\n            // console.log(\"Correct action\");\n            if (\"feedback\" in label.dataset) {\n                fb.textContent = jaxify(label.dataset.feedback);\n            } else {\n                fb.textContent = \"Correct!\";\n            }\n            label.classList.add(\"correctButton\");\n\n            fb.className = \"Feedback\";\n            fb.classList.add(\"correct\");\n\n        } else {\n            if (\"feedback\" in label.dataset) {\n                fb.textContent = jaxify(label.dataset.feedback);\n            } else {\n                fb.textContent = \"Incorrect -- try again.\";\n            }\n            //console.log(\"Error action\");\n            label.classList.add(\"incorrectButton\");\n            fb.className = \"Feedback\";\n            fb.classList.add(\"incorrect\");\n        }\n    }\n    else {\n        var reset = false;\n        var feedback;\n         if (label.dataset.correct == \"true\") {\n            if (\"feedback\" in label.dataset) {\n                feedback = jaxify(label.dataset.feedback);\n            } else {\n                feedback = \"Correct!\";\n            }\n            if (label.dataset.answered <= 0) {\n                if (fb.dataset.answeredcorrect < 0) {\n                    fb.dataset.answeredcorrect = 1;\n                    reset = true;\n                } else {\n                    fb.dataset.answeredcorrect++;\n                }\n                if (reset) {\n                    for (var i = 0; i < answers.length; i++) {\n                        var child = answers[i];\n                        child.className = \"MCButton\";\n                        child.dataset.answered = 0;\n                    }\n                }\n                label.classList.add(\"correctButton\");\n                label.dataset.answered = 1;\n                fb.className = \"Feedback\";\n                fb.classList.add(\"correct\");\n\n            }\n        } else {\n            if (\"feedback\" in label.dataset) {\n                feedback = jaxify(label.dataset.feedback);\n            } else {\n                feedback = \"Incorrect -- try again.\";\n            }\n            if (fb.dataset.answeredcorrect > 0) {\n                fb.dataset.answeredcorrect = -1;\n                reset = true;\n            } else {\n                fb.dataset.answeredcorrect--;\n            }\n\n            if (reset) {\n                for (var i = 0; i < answers.length; i++) {\n                    var child = answers[i];\n                    child.className = \"MCButton\";\n                    child.dataset.answered = 0;\n                }\n            }\n            label.classList.add(\"incorrectButton\");\n            fb.className = \"Feedback\";\n            fb.classList.add(\"incorrect\");\n        }\n        // What follows is for the saved responses stuff\n        var outerContainer = fb.parentElement.parentElement;\n        var responsesContainer = document.getElementById(\"responses\" + outerContainer.id);\n        if (responsesContainer) {\n            //console.log(responsesContainer);\n            var response = label.firstChild.innerText;\n            if (label.querySelector(\".QuizCode\")){\n                response+= label.querySelector(\".QuizCode\").firstChild.innerText;\n            }\n            console.log(response);\n            //console.log(document.getElementById(\"quizWrap\"+id));\n            var qnum = document.getElementById(\"quizWrap\"+id).dataset.qnum;\n            console.log(\"Question \" + qnum);\n            //console.log(id, \", got numcorrect=\",fb.dataset.numcorrect);\n            var responses=JSON.parse(responsesContainer.dataset.responses);\n            if (label.dataset.correct == \"true\") {\n                if (typeof(responses[qnum]) == \"object\"){\n                    if (!responses[qnum].includes(response))\n                        responses[qnum].push(response);\n                } else{\n                    responses[qnum]= [ response ];\n                }\n            } else {\n                responses[qnum]= response;\n            }\n            console.log(responses);\n            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));\n            printResponses(responsesContainer);\n        }\n        // End save responses stuff\n\n\n\n        var numcorrect = fb.dataset.numcorrect;\n        var answeredcorrect = fb.dataset.answeredcorrect;\n        if (answeredcorrect >= 0) {\n            fb.textContent = feedback + \" [\" + answeredcorrect + \"/\" + numcorrect + \"]\";\n        } else {\n            fb.textContent = feedback + \" [\" + 0 + \"/\" + numcorrect + \"]\";\n        }\n\n\n    }\n\n    if (typeof MathJax != 'undefined') {\n        var version = MathJax.version;\n        console.log('MathJax version', version);\n        if (version[0] == \"2\") {\n            MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n        } else if (version[0] == \"3\") {\n            MathJax.typeset([fb]);\n        }\n    } else {\n        console.log('MathJax not detected');\n    }\n\n}\n\nfunction make_mc(qa, shuffle_answers, outerqDiv, qDiv, aDiv, id) {\n    var shuffled;\n    if (shuffle_answers == \"True\") {\n        //console.log(shuffle_answers+\" read as true\");\n        shuffled = getRandomSubarray(qa.answers, qa.answers.length);\n    } else {\n        //console.log(shuffle_answers+\" read as false\");\n        shuffled = qa.answers;\n    }\n\n\n    var num_correct = 0;\n\n\n\n    shuffled.forEach((item, index, ans_array) => {\n        //console.log(answer);\n\n        // Make input element\n        var inp = document.createElement(\"input\");\n        inp.type = \"radio\";\n        inp.id = \"quizo\" + id + index;\n        inp.style = \"display:none;\";\n        aDiv.append(inp);\n\n        //Make label for input element\n        var lab = document.createElement(\"label\");\n        lab.className = \"MCButton\";\n        lab.id = id + '-' + index;\n        lab.onclick = check_mc;\n        var aSpan = document.createElement('span');\n        aSpan.classsName = \"\";\n        //qDiv.id=\"quizQn\"+id+index;\n        if (\"answer\" in item) {\n            aSpan.innerHTML = jaxify(item.answer);\n            //aSpan.innerHTML=item.answer;\n        }\n        lab.append(aSpan);\n\n        // Create div for code inside question\n        var codeSpan;\n        if (\"code\" in item) {\n            codeSpan = document.createElement('span');\n            codeSpan.id = \"code\" + id + index;\n            codeSpan.className = \"QuizCode\";\n            var codePre = document.createElement('pre');\n            codeSpan.append(codePre);\n            var codeCode = document.createElement('code');\n            codePre.append(codeCode);\n            codeCode.innerHTML = item.code;\n            lab.append(codeSpan);\n            //console.log(codeSpan);\n        }\n\n        //lab.textContent=item.answer;\n\n        // Set the data attributes for the answer\n        lab.setAttribute('data-correct', item.correct);\n        if (item.correct) {\n            num_correct++;\n        }\n        if (\"feedback\" in item) {\n            lab.setAttribute('data-feedback', item.feedback);\n        }\n        lab.setAttribute('data-answered', 0);\n\n        aDiv.append(lab);\n\n    });\n\n    if (num_correct > 1) {\n        outerqDiv.className = \"ManyChoiceQn\";\n    } else {\n        outerqDiv.className = \"MultipleChoiceQn\";\n    }\n\n    return num_correct;\n\n}\nfunction check_numeric(ths, event) {\n\n    if (event.keyCode === 13) {\n        ths.blur();\n\n        var id = ths.id.split('-')[0];\n\n        var submission = ths.value;\n        if (submission.indexOf('/') != -1) {\n            var sub_parts = submission.split('/');\n            //console.log(sub_parts);\n            submission = sub_parts[0] / sub_parts[1];\n        }\n        //console.log(\"Reader entered\", submission);\n\n        if (\"precision\" in ths.dataset) {\n            var precision = ths.dataset.precision;\n            // console.log(\"1:\", submission)\n            submission = Math.round((1 * submission + Number.EPSILON) * 10 ** precision) / 10 ** precision;\n            // console.log(\"Rounded to \", submission, \" precision=\", precision  );\n        }\n\n\n        //console.log(\"In check_numeric(), id=\"+id);\n        //console.log(event.srcElement.id)           \n        //console.log(event.srcElement.dataset.feedback)\n\n        var fb = document.getElementById(\"fb\" + id);\n        fb.style.display = \"none\";\n        fb.textContent = \"Incorrect -- try again.\";\n\n        var answers = JSON.parse(ths.dataset.answers);\n        //console.log(answers);\n\n        var defaultFB = \"\";\n        var correct;\n        var done = false;\n        answers.every(answer => {\n            //console.log(answer.type);\n\n            correct = false;\n            // if (answer.type==\"value\"){\n            if ('value' in answer) {\n                if (submission == answer.value) {\n                    if (\"feedback\" in answer) {\n                        fb.textContent = jaxify(answer.feedback);\n                    } else {\n                        fb.textContent = jaxify(\"Correct\");\n                    }\n                    correct = answer.correct;\n                    //console.log(answer.correct);\n                    done = true;\n                }\n                // } else if (answer.type==\"range\") {\n            } else if ('range' in answer) {\n                //console.log(answer.range);\n                if ((submission >= answer.range[0]) && (submission < answer.range[1])) {\n                    fb.textContent = jaxify(answer.feedback);\n                    correct = answer.correct;\n                    //console.log(answer.correct);\n                    done = true;\n                }\n            } else if (answer.type == \"default\") {\n                defaultFB = answer.feedback;\n            }\n            if (done) {\n                return false; // Break out of loop if this has been marked correct\n            } else {\n                return true; // Keep looking for case that includes this as a correct answer\n            }\n        });\n\n        if ((!done) && (defaultFB != \"\")) {\n            fb.innerHTML = jaxify(defaultFB);\n            //console.log(\"Default feedback\", defaultFB);\n        }\n\n        fb.style.display = \"block\";\n        if (correct) {\n            ths.className = \"Input-text\";\n            ths.classList.add(\"correctButton\");\n            fb.className = \"Feedback\";\n            fb.classList.add(\"correct\");\n        } else {\n            ths.className = \"Input-text\";\n            ths.classList.add(\"incorrectButton\");\n            fb.className = \"Feedback\";\n            fb.classList.add(\"incorrect\");\n        }\n\n        // What follows is for the saved responses stuff\n        var outerContainer = fb.parentElement.parentElement;\n        var responsesContainer = document.getElementById(\"responses\" + outerContainer.id);\n        if (responsesContainer) {\n            console.log(submission);\n            var qnum = document.getElementById(\"quizWrap\"+id).dataset.qnum;\n            //console.log(\"Question \" + qnum);\n            //console.log(id, \", got numcorrect=\",fb.dataset.numcorrect);\n            var responses=JSON.parse(responsesContainer.dataset.responses);\n            console.log(responses);\n            if (submission == ths.value){\n                responses[qnum]= submission;\n            } else {\n                responses[qnum]= ths.value + \"(\" + submission +\")\";\n            }\n            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));\n            printResponses(responsesContainer);\n        }\n        // End code to preserve responses\n\n        if (typeof MathJax != 'undefined') {\n            var version = MathJax.version;\n            console.log('MathJax version', version);\n            if (version[0] == \"2\") {\n                MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n            } else if (version[0] == \"3\") {\n                MathJax.typeset([fb]);\n            }\n        } else {\n            console.log('MathJax not detected');\n        }\n        return false;\n    }\n\n}\n\nfunction isValid(el, charC) {\n    //console.log(\"Input char: \", charC);\n    if (charC == 46) {\n        if (el.value.indexOf('.') === -1) {\n            return true;\n        } else if (el.value.indexOf('/') != -1) {\n            var parts = el.value.split('/');\n            if (parts[1].indexOf('.') === -1) {\n                return true;\n            }\n        }\n        else {\n            return false;\n        }\n    } else if (charC == 47) {\n        if (el.value.indexOf('/') === -1) {\n            if ((el.value != \"\") && (el.value != \".\")) {\n                return true;\n            } else {\n                return false;\n            }\n        } else {\n            return false;\n        }\n    } else if (charC == 45) {\n        var edex = el.value.indexOf('e');\n        if (edex == -1) {\n            edex = el.value.indexOf('E');\n        }\n\n        if (el.value == \"\") {\n            return true;\n        } else if (edex == (el.value.length - 1)) { // If just after e or E\n            return true;\n        } else {\n            return false;\n        }\n    } else if (charC == 101) { // \"e\"\n        if ((el.value.indexOf('e') === -1) && (el.value.indexOf('E') === -1) && (el.value.indexOf('/') == -1)) {\n            // Prev symbol must be digit or decimal point:\n            if (el.value.slice(-1).search(/\\d/) >= 0) {\n                return true;\n            } else if (el.value.slice(-1).search(/\\./) >= 0) {\n                return true;\n            } else {\n                return false;\n            }\n        } else {\n            return false;\n        }\n    } else {\n        if (charC > 31 && (charC < 48 || charC > 57))\n            return false;\n    }\n    return true;\n}\n\nfunction numeric_keypress(evnt) {\n    var charC = (evnt.which) ? evnt.which : evnt.keyCode;\n\n    if (charC == 13) {\n        check_numeric(this, evnt);\n    } else {\n        return isValid(this, charC);\n    }\n}\n\n\n\n\n\nfunction make_numeric(qa, outerqDiv, qDiv, aDiv, id) {\n\n\n\n    //console.log(answer);\n\n\n    outerqDiv.className = \"NumericQn\";\n    aDiv.style.display = 'block';\n\n    var lab = document.createElement(\"label\");\n    lab.className = \"InpLabel\";\n    lab.textContent = \"Type numeric answer here:\";\n    aDiv.append(lab);\n\n    var inp = document.createElement(\"input\");\n    inp.type = \"text\";\n    //inp.id=\"input-\"+id;\n    inp.id = id + \"-0\";\n    inp.className = \"Input-text\";\n    inp.setAttribute('data-answers', JSON.stringify(qa.answers));\n    if (\"precision\" in qa) {\n        inp.setAttribute('data-precision', qa.precision);\n    }\n    aDiv.append(inp);\n    //console.log(inp);\n\n    //inp.addEventListener(\"keypress\", check_numeric);\n    //inp.addEventListener(\"keypress\", numeric_keypress);\n    /*\n    inp.addEventListener(\"keypress\", function(event) {\n        return numeric_keypress(this, event);\n    }\n                        );\n                        */\n    //inp.onkeypress=\"return numeric_keypress(this, event)\";\n    inp.onkeypress = numeric_keypress;\n    inp.onpaste = event => false;\n\n    inp.addEventListener(\"focus\", function (event) {\n        this.value = \"\";\n        return false;\n    }\n    );\n\n\n}\nfunction jaxify(string) {\n    var mystring = string;\n\n    var count = 0;\n    var loc = mystring.search(/([^\\\\]|^)(\\$)/);\n\n    var count2 = 0;\n    var loc2 = mystring.search(/([^\\\\]|^)(\\$\\$)/);\n\n    //console.log(loc);\n\n    while ((loc >= 0) || (loc2 >= 0)) {\n\n        /* Have to replace all the double $$ first with current implementation */\n        if (loc2 >= 0) {\n            if (count2 % 2 == 0) {\n                mystring = mystring.replace(/([^\\\\]|^)(\\$\\$)/, \"$1\\\\[\");\n            } else {\n                mystring = mystring.replace(/([^\\\\]|^)(\\$\\$)/, \"$1\\\\]\");\n            }\n            count2++;\n        } else {\n            if (count % 2 == 0) {\n                mystring = mystring.replace(/([^\\\\]|^)(\\$)/, \"$1\\\\(\");\n            } else {\n                mystring = mystring.replace(/([^\\\\]|^)(\\$)/, \"$1\\\\)\");\n            }\n            count++;\n        }\n        loc = mystring.search(/([^\\\\]|^)(\\$)/);\n        loc2 = mystring.search(/([^\\\\]|^)(\\$\\$)/);\n        //console.log(mystring,\", loc:\",loc,\", loc2:\",loc2);\n    }\n\n    //console.log(mystring);\n    return mystring;\n}\n\n\nfunction show_questions(json, mydiv) {\n    console.log('show_questions');\n    //var mydiv=document.getElementById(myid);\n    var shuffle_questions = mydiv.dataset.shufflequestions;\n    var num_questions = mydiv.dataset.numquestions;\n    var shuffle_answers = mydiv.dataset.shuffleanswers;\n    var max_width = mydiv.dataset.maxwidth;\n\n    if (num_questions > json.length) {\n        num_questions = json.length;\n    }\n\n    var questions;\n    if ((num_questions < json.length) || (shuffle_questions == \"True\")) {\n        //console.log(num_questions+\",\"+json.length);\n        questions = getRandomSubarray(json, num_questions);\n    } else {\n        questions = json;\n    }\n\n    //console.log(\"SQ: \"+shuffle_questions+\", NQ: \" + num_questions + \", SA: \", shuffle_answers);\n\n    // Iterate over questions\n    questions.forEach((qa, index, array) => {\n        //console.log(qa.question); \n\n        var id = makeid(8);\n        //console.log(id);\n\n\n        // Create Div to contain question and answers\n        var iDiv = document.createElement('div');\n        //iDiv.id = 'quizWrap' + id + index;\n        iDiv.id = 'quizWrap' + id;\n        iDiv.className = 'Quiz';\n        iDiv.setAttribute('data-qnum', index);\n        iDiv.style.maxWidth  =max_width+\"px\";\n        mydiv.appendChild(iDiv);\n        // iDiv.innerHTML=qa.question;\n        \n        var outerqDiv = document.createElement('div');\n        outerqDiv.id = \"OuterquizQn\" + id + index;\n        // Create div to contain question part\n        var qDiv = document.createElement('div');\n        qDiv.id = \"quizQn\" + id + index;\n        \n        if (qa.question) {\n            iDiv.append(outerqDiv);\n\n            //qDiv.textContent=qa.question;\n            qDiv.innerHTML = jaxify(qa.question);\n            outerqDiv.append(qDiv);\n        }\n\n        // Create div for code inside question\n        var codeDiv;\n        if (\"code\" in qa) {\n            codeDiv = document.createElement('div');\n            codeDiv.id = \"code\" + id + index;\n            codeDiv.className = \"QuizCode\";\n            var codePre = document.createElement('pre');\n            codeDiv.append(codePre);\n            var codeCode = document.createElement('code');\n            codePre.append(codeCode);\n            codeCode.innerHTML = qa.code;\n            outerqDiv.append(codeDiv);\n            //console.log(codeDiv);\n        }\n\n\n        // Create div to contain answer part\n        var aDiv = document.createElement('div');\n        aDiv.id = \"quizAns\" + id + index;\n        aDiv.className = 'Answer';\n        iDiv.append(aDiv);\n\n        //console.log(qa.type);\n\n        var num_correct;\n        if ((qa.type == \"multiple_choice\") || (qa.type == \"many_choice\") ) {\n            num_correct = make_mc(qa, shuffle_answers, outerqDiv, qDiv, aDiv, id);\n            if (\"answer_cols\" in qa) {\n                //aDiv.style.gridTemplateColumns = 'auto '.repeat(qa.answer_cols);\n                aDiv.style.gridTemplateColumns = 'repeat(' + qa.answer_cols + ', 1fr)';\n            }\n        } else if (qa.type == \"numeric\") {\n            //console.log(\"numeric\");\n            make_numeric(qa, outerqDiv, qDiv, aDiv, id);\n        }\n\n\n        //Make div for feedback\n        var fb = document.createElement(\"div\");\n        fb.id = \"fb\" + id;\n        //fb.style=\"font-size: 20px;text-align:center;\";\n        fb.className = \"Feedback\";\n        fb.setAttribute(\"data-answeredcorrect\", 0);\n        fb.setAttribute(\"data-numcorrect\", num_correct);\n        iDiv.append(fb);\n\n\n    });\n    var preserveResponses = mydiv.dataset.preserveresponses;\n    console.log(preserveResponses);\n    console.log(preserveResponses == \"true\");\n    if (preserveResponses == \"true\") {\n        console.log(preserveResponses);\n        // Create Div to contain record of answers\n        var iDiv = document.createElement('div');\n        iDiv.id = 'responses' + mydiv.id;\n        iDiv.className = 'JCResponses';\n        // Create a place to store responses as an empty array\n        iDiv.setAttribute('data-responses', '[]');\n\n        // Dummy Text\n        iDiv.innerHTML=\"<b>Select your answers and then follow the directions that will appear here.</b>\"\n        //iDiv.className = 'Quiz';\n        mydiv.appendChild(iDiv);\n    }\n//console.log(\"At end of show_questions\");\n    if (typeof MathJax != 'undefined') {\n        console.log(\"MathJax version\", MathJax.version);\n        var version = MathJax.version;\n        setTimeout(function(){\n            var version = MathJax.version;\n            console.log('After sleep, MathJax version', version);\n            if (version[0] == \"2\") {\n                MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n            } else if (version[0] == \"3\") {\n                MathJax.typeset([mydiv]);\n            }\n        }, 500);\nif (typeof version == 'undefined') {\n        } else\n        {\n            if (version[0] == \"2\") {\n                MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n            } else if (version[0] == \"3\") {\n                MathJax.typeset([mydiv]);\n            } else {\n                console.log(\"MathJax not found\");\n            }\n        }\n    }\n    return false;\n}\n/* This is to handle asynchrony issues in loading Jupyter notebooks\n           where the quiz has been previously run. The Javascript was generally\n           being run before the div was added to the DOM. I tried to do this\n           more elegantly using Mutation Observer, but I didn't get it to work.\n\n           Someone more knowledgeable could make this better ;-) */\n\n        function try_show() {\n          if(document.getElementById(\"NDPrPDZfUpbR\")) {\n            show_questions(questionsNDPrPDZfUpbR,  NDPrPDZfUpbR); \n          } else {\n             setTimeout(try_show, 200);\n          }\n        };\n    \n        {\n        // console.log(element);\n\n        //console.log(\"NDPrPDZfUpbR\");\n        // console.log(document.getElementById(\"NDPrPDZfUpbR\"));\n\n        try_show();\n        }\n        ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from jupyterquiz import display_quiz\n",
    "display_quiz(\"assets/transformers_questions.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
